import base64
import openai
import os
from fastapi import FastAPI, UploadFile, File
from fastapi.middleware.cors import CORSMiddleware
from typing import Dict
from dotenv import load_dotenv

load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

app = FastAPI()

# üëá  —Å—é–¥–∞ —Å–≤–æ–π —Ñ—Ä–æ–Ω—Ç–µ–Ω–¥-–¥–æ–º–µ–Ω
origins = [
    "https://ai-instagram-helper-git-main-ihor555s-projects.vercel.app",
    "http://localhost:3000",  # –Ω–∞ —Å–ª—É—á–∞–π –ª–æ–∫–∞–ª—å–Ω–æ–π –æ—Ç–ª–∞–¥–∫–∏
]

app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,  # üëà —Ç—É—Ç —Å–ø–∏—Å–æ–∫ —Ä–∞–∑—Ä–µ—à—ë–Ω–Ω—ã—Ö –¥–æ–º–µ–Ω–æ–≤
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.post("/analyze")
async def analyze_image(image: UploadFile = File(...)) -> Dict[str, str]:
    contents = await image.read()
    base64_image = base64.b64encode(contents).decode("utf-8")

    try:
        response = openai.chat.completions.create(
            model="gpt-4o",
            messages=[
                {
                    "role": "user",
                    "content": [
                        { "type": "text", "text": "–ß—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–æ –Ω–∞ —ç—Ç–æ–º —Ñ–æ—Ç–æ? –°–≥–µ–Ω–µ—Ä–∏—Ä—É–π –∫–æ—Ä–æ—Ç–∫–∏–π caption –∏ —Ö–µ—à—Ç–µ–≥–∏ –Ω–∞ —Ä—É—Å—Å–∫–æ–º." },
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{base64_image}"
                            },
                        },
                    ],
                }
            ],
            max_tokens=300,
        )

        result = response.choices[0].message.content
        return {
            "caption": result,
            "hashtags": ""  # –≤—ã–¥–µ–ª–∏—Ç—å –æ—Ç–¥–µ–ª—å–Ω–æ
        }

    except Exception as e:
        return {"status": "error", "detail": str(e)}
